
	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = as.formula(paste0("Surv(combined_data$OS_days, censored_os) ~ ",     gene_variables)), data = combined_data, family = Loglog(),     center = TRUE, control = boost_control(mstop = 500))


	 Negative Log Logistic Likelihood 

Loss function:  

Number of boosting iterations: mstop = 500 
Step size:  0.1 
Offset:  8.362795 

Coefficients: 
  (Intercept)        SLC1A4       SLC38A5       SLC43A2        SLC7A7       SLC36A1       SLC7A10 
 1.2681608042 -0.0055314911 -0.1534810212  0.0008965708 -0.2047321489 -0.2272000898 -0.0035235948 
      SLC36A2       SLC7A11        SLC7A9       SLC6A14        SLC3A1       SLC6A20       SLC6A18 
 8.0329351583  0.0141809617  1.7407761587 18.1642598453  1.1715080231  1.8963762764  5.2125455992 
attr(,"offset")
[1] 8.362795

Selection frequencies:
     SLC7A7 (Intercept)     SLC38A5     SLC6A20      SLC7A9     SLC6A14     SLC36A1     SLC7A11 
      0.168       0.148       0.140       0.132       0.092       0.092       0.090       0.072 
     SLC1A4     SLC36A2      SLC3A1     SLC43A2     SLC7A10     SLC6A18 
      0.018       0.016       0.014       0.010       0.004       0.004 

